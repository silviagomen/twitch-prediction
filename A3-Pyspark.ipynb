{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72effe07-a2fd-4876-8e3a-53a6a72ea456",
   "metadata": {},
   "source": [
    "# Assignment 3 - Steps 2 and 3: Text preprocessing and construction of predictive model\n",
    "\n",
    "\n",
    "Group 11:\n",
    "- Lisa Driessen - r0675727\n",
    "- Laura Fernández López - r0877908\n",
    "- Silvia María Goñi Mendia - r0877434\n",
    "- Peter Day - r0866276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fedb16-1c1a-4653-874a-7a04b93fa0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, StringIndexer, HashingTF, IDF, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b63bff-3552-45e7-927f-14aad687d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('A3-2') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154ef195-0422-4590-a439-3c59f8971de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.101:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>A3-2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff180ce7040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9f694-96f2-4eb4-9a62-ed0483dbfd97",
   "metadata": {},
   "source": [
    "## Import data and assign target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0222051f-0b05-451e-afac-5f079276d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"messages.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7094763-5797-4f20-b407-7bfb31a68ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"messages_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbbd2e0c-6d88-41d4-8e4c-71408f3f2975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+-------------------------------------------------------------+\n",
      "|username        |channel   |message                                                      |\n",
      "+----------------+----------+-------------------------------------------------------------+\n",
      "|fossabot        |#loltyler1|@KuniGaru, ACCOUNTS: BIG TONKA T is currently Master I 111 LP|\n",
      "|xsageone        |#jinnytty |exbcSpy                                                      |\n",
      "|widedomi        |#jinnytty |3Head                                                        |\n",
      "|skysage         |#jinnytty |no                                                           |\n",
      "|przemkowsky_wawa|#jinnytty |HYPERS                                                       |\n",
      "+----------------+----------+-------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+----------+---------------------------------------------------------+\n",
      "|username          |channel   |message                                                  |\n",
      "+------------------+----------+---------------------------------------------------------+\n",
      "|yugenmugen        |#jinnytty |Cocklklklkle                                             |\n",
      "|quote_if_t1_inting|#loltyler1|chat going so slow i can use this emote tyler1H1 tyler1H2|\n",
      "|kaperyap          |#jinnytty |YUM                                                      |\n",
      "|dead_teeth        |#jinnytty |peepoPopcorn                                             |\n",
      "|vincentt23        |#jinnytty |yyjTasty 󠀀                                              |\n",
      "+------------------+----------+---------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, False)\n",
    "df_test.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd99cd-a8f5-4160-9f66-f14811c5f0a4",
   "metadata": {},
   "source": [
    "## Step 2: Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4db64df8-6962-40c1-bdaf-c9a31393449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label column\n",
    "df = StringIndexer(inputCol='channel', outputCol='label', handleInvalid='keep').fit(df).transform(df)\n",
    "df_test = StringIndexer(inputCol='channel', outputCol='label', handleInvalid='keep').fit(df_test).transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3de02481-0da4-423e-a389-8acccd14e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with both the username and the message (Not used)\n",
    "df = df.withColumn('message0', f.concat(f.col('username'),f.lit(' '),f.col('message')))\n",
    "df_test = df_test.withColumn('message0', f.concat(f.col('username'),f.lit(' '),f.col('message')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7eeef671-c937-40e5-b01f-9b4f0cec1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove symbols\n",
    "df = df.withColumn(\"words1\", f.regexp_replace(f.col(\"message0\"), \"[\\$#,<>+@=?!]\", \"\"))\n",
    "df_test = df_test.withColumn(\"words1\", f.regexp_replace(f.col(\"message0\"), \"[\\$#,<>+@=?!]\", \"\"))\n",
    "\n",
    "# Remove extra spaces\n",
    "df = df.withColumn(\"words2\", f.regexp_replace(f.col(\"words1\"), \"  +\", \" \"))\n",
    "df_test = df_test.withColumn(\"words2\", f.regexp_replace(f.col(\"words1\"), \"  +\", \" \"))\n",
    "\n",
    "# Remove missing values\n",
    "df = df.dropna()\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = Tokenizer(inputCol=\"words2\", outputCol=\"words3\")\n",
    "df = tokenizer.transform(df)\n",
    "df_test = tokenizer.transform(df_test)\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol=\"words3\", outputCol=\"words\")\n",
    "df = remover.transform(df)\n",
    "df_test = remover.transform(df_test)\n",
    "\n",
    "df = df.drop(*(\"username\", \"channel\", \"message\", \"words1\", \"words2\", \"words3\"))\n",
    "df_test = df_test.drop(*(\"username\", \"channel\", \"message\", \"words1\", \"words2\", \"words3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41508f60-41fb-4e4e-8577-c0183034c3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|label|message0                                                              |words                                                                  |\n",
      "+-----+----------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|1.0  |fossabot @KuniGaru, ACCOUNTS: BIG TONKA T is currently Master I 111 LP|[fossabot, kunigaru, accounts:, big, tonka, currently, master, 111, lp]|\n",
      "|0.0  |xsageone exbcSpy                                                      |[xsageone, exbcspy]                                                    |\n",
      "|0.0  |widedomi 3Head                                                        |[widedomi, 3head]                                                      |\n",
      "|0.0  |skysage no                                                            |[skysage]                                                              |\n",
      "|0.0  |przemkowsky_wawa HYPERS                                               |[przemkowsky_wawa, hypers]                                             |\n",
      "+-----+----------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+----------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|label|message0                                                                    |words                                                                  |\n",
      "+-----+----------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
      "|0.0  |yugenmugen Cocklklklkle                                                     |[yugenmugen, cocklklklkle]                                             |\n",
      "|1.0  |quote_if_t1_inting chat going so slow i can use this emote tyler1H1 tyler1H2|[quote_if_t1_inting, chat, going, slow, use, emote, tyler1h1, tyler1h2]|\n",
      "|0.0  |kaperyap YUM                                                                |[kaperyap, yum]                                                        |\n",
      "|0.0  |dead_teeth peepoPopcorn                                                     |[dead_teeth, peepopopcorn]                                             |\n",
      "|0.0  |vincentt23 yyjTasty 󠀀                                                      |[vincentt23, yyjtasty, 󠀀]                                             |\n",
      "+-----+----------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, False)\n",
    "df_test.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79ad75-af5d-4178-bfe7-8fa04bb281f3",
   "metadata": {},
   "source": [
    "## Step 3: Predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df1022-7174-4ed0-9bde-c557d6c2eb1f",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76be624b-554f-4a25-95cd-db274741c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(df)\n",
    "featurizedData_test = hashingTF.transform(df_test)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"tfidf\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "df = idfModel.transform(featurizedData)\n",
    "\n",
    "df_test = idfModel.transform(featurizedData_test)\n",
    "\n",
    "df = df.drop(\"rawFeatures\")\n",
    "df_test = df_test.drop(\"rawFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67541d7-927b-49c6-9bda-1af049f44022",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd9da862-6ed3-4026-a88e-eb310d919c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=10, minCount=0, inputCol=\"words\", outputCol=\"w2v\")\n",
    "w2vmodel = word2Vec.fit(df)\n",
    "\n",
    "df = w2vmodel.transform(df)\n",
    "df_test = w2vmodel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e4eadaf-32ee-4bb2-83ff-181fb1a5e0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|            message0|               words|               tfidf|                 w2v|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1.0|fossabot @KuniGar...|[fossabot, kuniga...|(20,[4,6,7,8,19],...|[1.27302299605475...|\n",
      "|  0.0|    xsageone exbcSpy| [xsageone, exbcspy]|(20,[9,19],[2.033...|[-0.0458895324263...|\n",
      "|  0.0|      widedomi 3Head|   [widedomi, 3head]|(20,[5,14],[2.214...|[0.11197673529386...|\n",
      "|  0.0|          skysage no|           [skysage]|(20,[3],[2.001902...|[-0.7380989193916...|\n",
      "|  0.0|przemkowsky_wawa ...|[przemkowsky_wawa...|(20,[4,9],[1.8839...|[-0.1244265735149...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|            message0|               words|               tfidf|                 w2v|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0.0|yugenmugen Cocklk...|[yugenmugen, cock...|(20,[0,7],[1.8019...|[0.0,0.0,0.0,0.0,...|\n",
      "|  1.0|quote_if_t1_intin...|[quote_if_t1_inti...|(20,[3,9,13,16,18...|[0.08225324098020...|\n",
      "|  0.0|        kaperyap YUM|     [kaperyap, yum]|(20,[3,18],[2.001...|[0.02289738692343...|\n",
      "|  0.0|dead_teeth peepoP...|[dead_teeth, peep...|(20,[12,14],[1.54...|[-0.0355421807616...|\n",
      "|  0.0|vincentt23 yyjTas...|[vincentt23, yyjt...|(20,[0,11,17],[1....|[-0.5324508349100...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fe2124f-9264-48d5-bb3f-3151d48e61f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 52864\n",
      "Validation Dataset Count: 22447\n",
      "Test Dataset Count: 31702\n"
     ]
    }
   ],
   "source": [
    "# Split data in train and test sets\n",
    "df_train, df_val = df.randomSplit([0.7, 0.3], seed = 234)\n",
    "print(\"Training Dataset Count: \" + str(df_train.count()))\n",
    "print(\"Validation Dataset Count: \" + str(df_val.count()))\n",
    "print(\"Test Dataset Count: \" + str(df_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9c2f7-7f3a-403f-aadb-29890fadfb7d",
   "metadata": {},
   "source": [
    "### Logistic Regression for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a77bb582-b735-4c6e-a8d6-93874eca3c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------------------------------------------------------------+\n",
      "|label|prediction|probability                                                    |\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "|0.0  |0.0       |[0.7054291377886421,0.2945708622034997,7.858186408890208E-12]  |\n",
      "|0.0  |1.0       |[0.49013392711900167,0.5098660728714622,9.53620387867034E-12]  |\n",
      "|0.0  |1.0       |[0.4531347354374585,0.5468652645507329,1.1808612580289882E-11] |\n",
      "|0.0  |0.0       |[0.6886984843661735,0.3113015156243836,9.442982621421199E-12]  |\n",
      "|0.0  |0.0       |[0.6316728118202544,0.36832718816903715,1.0708555048481399E-11]|\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Train set accuracy = 0.6367660411622276\n",
      "+-----+----------+--------------------------------------------------------------+\n",
      "|label|prediction|probability                                                   |\n",
      "+-----+----------+--------------------------------------------------------------+\n",
      "|0.0  |0.0       |[0.6324267534568225,0.3675732465342416,8.935786522899753E-12] |\n",
      "|0.0  |1.0       |[0.4853332039444132,0.5146667960427157,1.2870991339494144E-11]|\n",
      "|0.0  |0.0       |[0.7015141278195718,0.29848587217237527,8.053016612436758E-12]|\n",
      "|0.0  |0.0       |[0.638695326635648,0.361304673352622,1.1730182403011225E-11]  |\n",
      "|0.0  |0.0       |[0.7236661158374003,0.2763338841558291,6.77064735383472E-12]  |\n",
      "+-----+----------+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Validation set accuracy = 0.6406646767942265\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "|label|prediction|probability                                                    |\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "|0.0  |0.0       |[0.7141841200903525,0.28581587990287205,6.775529837072869E-12] |\n",
      "|1.0  |1.0       |[0.4382059057353843,0.561794094246703,1.7912615267358148E-11]  |\n",
      "|0.0  |0.0       |[0.656143726914487,0.34385627307792305,7.589956034968308E-12]  |\n",
      "|0.0  |0.0       |[0.5605888763424011,0.43941112364686247,1.0736442353783761E-11]|\n",
      "|0.0  |0.0       |[0.691538613223302,0.30846138676660495,1.0093016735426594E-11] |\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy = 0.6173427544003532\n"
     ]
    }
   ],
   "source": [
    "# Apply logistic regression model\n",
    "lr_tfidf = LogisticRegression(featuresCol = 'tfidf', labelCol='label').fit(df_train)\n",
    "\n",
    "# Train Results\n",
    "train_results_tfidf = lr_tfidf.evaluate(df_train).predictions\n",
    "train_results_tfidf.select(['label','prediction','probability']).show(5,False)\n",
    "\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(train_results_tfidf)\n",
    "print(\"Train set accuracy = \" + str(accuracy))\n",
    "\n",
    "# Validation Results\n",
    "val_lr_tfidf = lr_tfidf.transform(df_val)\n",
    "val_lr_tfidf.select(['label','prediction','probability']).show(5, False)\n",
    "\n",
    "accuracy = evaluator_acc.evaluate(val_lr_tfidf)\n",
    "print(\"Validation set accuracy = \" + str(accuracy))\n",
    "\n",
    "# Test Results\n",
    "pred_lr_tfidf = lr_tfidf.transform(df_test)\n",
    "pred_lr_tfidf.select(['label','prediction','probability']).show(5, False)\n",
    "\n",
    "accuracy = evaluator_acc.evaluate(pred_lr_tfidf)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613649b-9498-433f-948d-780f514d7d95",
   "metadata": {},
   "source": [
    "### Logistic Regression for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a18af87-e4f1-49db-bab5-e03a93362572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------------------------------------------------------------+\n",
      "|label|prediction|probability                                                    |\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "|0.0  |0.0       |[0.7927476905908345,0.20725230940875863,4.0688827966079027E-13]|\n",
      "|0.0  |0.0       |[0.7541796706691013,0.24582032932888845,2.010404189421244E-12] |\n",
      "|0.0  |0.0       |[0.9881052292058464,0.011894770763522123,3.063144260542358E-11]|\n",
      "|0.0  |0.0       |[0.7451198215158286,0.2548801784822799,1.891342121408406E-12]  |\n",
      "|0.0  |0.0       |[0.9677191430591785,0.032280856939991706,8.298317777190093E-13]|\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Train set accuracy = 0.8130864104116223\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "|label|prediction|probability                                                    |\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "|0.0  |0.0       |[0.6167718688500925,0.38322813114883925,1.0683698235591442E-12]|\n",
      "|0.0  |0.0       |[0.6239824723086594,0.37601752768882296,2.517694632788934E-12] |\n",
      "|0.0  |0.0       |[0.7805626873724874,0.21943731262549288,2.0197937566171048E-12]|\n",
      "|0.0  |1.0       |[0.41336987766049177,0.5866301223382321,1.2761062509628436E-12]|\n",
      "|0.0  |0.0       |[0.9809002353617897,0.019099764635763895,2.446262751778833E-12]|\n",
      "+-----+----------+---------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy = 0.8148973136722056\n",
      "+-----+----------+-----------------------------------------------------------------+\n",
      "|label|prediction|probability                                                      |\n",
      "+-----+----------+-----------------------------------------------------------------+\n",
      "|0.0  |0.0       |[0.5565197277410503,0.44348027225781117,1.1385856927363257E-12]  |\n",
      "|1.0  |1.0       |[0.4654594165829706,0.5345405834156725,1.357051257666222E-12]    |\n",
      "|0.0  |1.0       |[0.4783296167808523,0.5216703832181151,1.03269021004537E-12]     |\n",
      "|0.0  |0.0       |[0.9715862574298688,0.028413742565301336,4.829887747295278E-12]  |\n",
      "|0.0  |0.0       |[0.9999876358177159,1.2364130074522217E-5,5.2209602126535314E-11]|\n",
      "+-----+----------+-----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy = 0.7649675099362816\n"
     ]
    }
   ],
   "source": [
    "# Apply logistic regression model\n",
    "lr_w2v = LogisticRegression(featuresCol = 'w2v', labelCol='label').fit(df_train)\n",
    "\n",
    "# Train Results\n",
    "train_results_w2v = lr_w2v.evaluate(df_train).predictions\n",
    "train_results_w2v.select(['label','prediction','probability']).show(5, False)\n",
    "\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(train_results_w2v)\n",
    "print(\"Train set accuracy = \" + str(accuracy))\n",
    "\n",
    "# Validation Results\n",
    "val_lr_w2v = lr_w2v.transform(df_val)\n",
    "val_lr_w2v.select(['label','prediction','probability']).show(5, False)\n",
    "\n",
    "accuracy = evaluator_acc.evaluate(val_lr_w2v)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# Test Results\n",
    "pred_lr_w2v = lr_w2v.transform(df_test)\n",
    "pred_lr_w2v.select(['label','prediction','probability']).show(5, False)\n",
    "\n",
    "accuracy = evaluator_acc.evaluate(pred_lr_w2v)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07165887-9537-420c-a1e0-c753a92132ac",
   "metadata": {},
   "source": [
    "### Naive Bayes with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "801138b5-3e23-4a02-85aa-e055746d851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0.0  |0.0       |[0.6903376430998165,0.3096623569001834] |\n",
      "|0.0  |1.0       |[0.4607557609730969,0.5392442390269031] |\n",
      "|0.0  |1.0       |[0.2812955686549889,0.7187044313450112] |\n",
      "|0.0  |0.0       |[0.9686056315004665,0.03139436849953342]|\n",
      "|0.0  |0.0       |[0.6768611349646294,0.32313886503537065]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Train set accuracy = 0.6108126513317191\n",
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0.0  |0.0       |[0.5286629730643598,0.47133702693564017]|\n",
      "|0.0  |0.0       |[0.5688847699936724,0.4311152300063277] |\n",
      "|0.0  |0.0       |[0.6719160932473748,0.32808390675262517]|\n",
      "|0.0  |1.0       |[0.4483994606781926,0.5516005393218074] |\n",
      "|0.0  |0.0       |[0.7784832322903814,0.2215167677096186] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Validation set accuracy = 0.610905688956208\n",
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0.0  |0.0       |[0.6971132362396623,0.30288676376033774]|\n",
      "|1.0  |0.0       |[0.7743081088966777,0.22569189110332222]|\n",
      "|0.0  |0.0       |[0.6092326560667563,0.3907673439332438] |\n",
      "|0.0  |0.0       |[0.5067392677811451,0.4932607322188551] |\n",
      "|0.0  |0.0       |[0.7529716498282437,0.24702835017175634]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy = 0.5824238218408934\n"
     ]
    }
   ],
   "source": [
    "# Create trainer and set parameters\n",
    "nb_tfidf = NaiveBayes(featuresCol = 'tfidf', labelCol='label', smoothing=1.0).fit(df)\n",
    "\n",
    "train_nb_tfidf = nb_tfidf.transform(df_train)\n",
    "train_nb_tfidf.select(['label','prediction','probability']).show(5, False)\n",
    "# Compute accuracy on train set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(train_nb_tfidf)\n",
    "print(\"Train set accuracy = \" + str(accuracy))\n",
    "\n",
    "val_nb_tfidf = nb_tfidf.transform(df_val)\n",
    "val_nb_tfidf.select(['label','prediction','probability']).show(5, False)\n",
    "# Compute accuracy on validation set\n",
    "accuracy = evaluator.evaluate(val_nb_tfidf)\n",
    "print(\"Validation set accuracy = \" + str(accuracy))\n",
    "\n",
    "pred_nb_tfidf = nb_tfidf.transform(df_test)\n",
    "pred_nb_tfidf.select(['label','prediction','probability']).show(5, False)\n",
    "# Compute accuracy on test set\n",
    "accuracy = evaluator.evaluate(pred_nb_tfidf)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4377ece-5c63-49ee-bd90-ed4025098ee1",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "493eadd0-bf4c-4cf7-85b7-8cb000cec1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_w2v.save(\"A3.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
