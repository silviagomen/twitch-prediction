{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Step 4: Prediction\n",
    "Group 11:\n",
    "- Lisa Driessen - r0675727\n",
    "- Laura Fernández López - r0877908\n",
    "- Silvia María Goñi Mendia - r0877434\n",
    "- Peter Day - r0866276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.101:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.101:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc7b0575b20>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, StringIndexer, HashingTF, IDF, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = False\n",
    "globals()['my_model'] = None\n",
    "\n",
    "\n",
    "def predict(df):\n",
    "    # Preprocessing\n",
    "    df.show()\n",
    "    df = StringIndexer(inputCol='channel', outputCol='label', handleInvalid='keep').fit(df).transform(df)\n",
    "    df = df.withColumn('message0', f.concat(f.col('username'),f.lit(' '),f.col('message')))\n",
    "    df = df.withColumn(\"words1\", f.regexp_replace(f.col(\"message0\"), \"[\\$#,<>+@=?!]\", \"\"))\n",
    "    df = df.withColumn(\"words2\", f.regexp_replace(f.col(\"words1\"), \"  +\", \" \"))\n",
    "    df = df.dropna()\n",
    "    tokenizer = Tokenizer(inputCol=\"words2\", outputCol=\"words3\")\n",
    "    df = tokenizer.transform(df)\n",
    "    remover = StopWordsRemover(inputCol=\"words3\", outputCol=\"words\")\n",
    "    df = remover.transform(df)\n",
    "    word2Vec = Word2Vec(vectorSize=10, minCount=0, inputCol=\"words\", outputCol=\"w2v\")\n",
    "    w2vmodel = word2Vec.fit(df)\n",
    "    df = w2vmodel.transform(df)\n",
    "    # Predict\n",
    "    df_result = globals()['my_model'].transform(df)\n",
    "    df_result = df_result.drop(*(\"username\", \"words\", \"message0\", \"channel\", \"words1\", \"words2\", \"words3\", \"datetime\", \"w2v\"))\n",
    "    df_result.show()\n",
    "    return(df_result)\n",
    "\n",
    "predict_udf = udf(predict, StringType())\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        print(\"Loading the model!\")\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = LogisticRegressionModel.load(\"A3.model\")\n",
    "        globals()['models_loaded'] = True\n",
    "    #else:\n",
    "        print(\"Model's already loaded\")\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show(n=3)\n",
    "    \n",
    "    # Utilize our predict function\n",
    "    predictions = predict(df)\n",
    "    predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"localhost\", 8080)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2022-05-29 12:20:10 =========\n",
      "Loading the model!\n",
      "Model's already loaded\n",
      "+---------+--------------------+--------------------+--------+\n",
      "|  channel|            datetime|             message|username|\n",
      "+---------+--------------------+--------------------+--------+\n",
      "|#jinnytty|2022-05-29T10:20:...|                 yes|   v2ran|\n",
      "|#jinnytty|2022-05-29T10:20:...|            Clueless| mesh_17|\n",
      "|#jinnytty|2022-05-29T10:20:...|guyfromswitzerlan...| jorgrim|\n",
      "+---------+--------------------+--------------------+--------+\n",
      "\n",
      "+---------+--------------------+--------------------+--------+\n",
      "|  channel|            datetime|             message|username|\n",
      "+---------+--------------------+--------------------+--------+\n",
      "|#jinnytty|2022-05-29T10:20:...|                 yes|   v2ran|\n",
      "|#jinnytty|2022-05-29T10:20:...|            Clueless| mesh_17|\n",
      "|#jinnytty|2022-05-29T10:20:...|guyfromswitzerlan...| jorgrim|\n",
      "+---------+--------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|             message|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|                 yes|  0.0|[8.89869569456102...|[0.57317590306392...|       0.0|\n",
      "|            Clueless|  0.0|[8.98592539053067...|[0.53327532540359...|       0.0|\n",
      "|guyfromswitzerlan...|  0.0|[9.05674753646123...|[0.59642602083634...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|             message|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|                 yes|  0.0|[8.89869569456102...|[0.57317590306392...|       0.0|\n",
      "|            Clueless|  0.0|[8.98592539053067...|[0.53327532540359...|       0.0|\n",
      "|guyfromswitzerlan...|  0.0|[9.05674753646123...|[0.59642602083634...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "\n",
      "========= 2022-05-29 12:20:20 =========\n",
      "+---------+--------------------+--------+------------------+\n",
      "|  channel|            datetime| message|          username|\n",
      "+---------+--------------------+--------+------------------+\n",
      "|#jinnytty|2022-05-29T10:20:...|LETSGOOO|guyfromswitzerland|\n",
      "+---------+--------------------+--------+------------------+\n",
      "\n",
      "+---------+--------------------+--------+------------------+\n",
      "|  channel|            datetime| message|          username|\n",
      "+---------+--------------------+--------+------------------+\n",
      "|#jinnytty|2022-05-29T10:20:...|LETSGOOO|guyfromswitzerland|\n",
      "+---------+--------------------+--------+------------------+\n",
      "\n",
      "+--------+-----+--------------------+--------------------+----------+\n",
      "| message|label|       rawPrediction|         probability|prediction|\n",
      "+--------+-----+--------------------+--------------------+----------+\n",
      "|LETSGOOO|  0.0|[8.88758229630753...|[0.51292127140227...|       0.0|\n",
      "+--------+-----+--------------------+--------------------+----------+\n",
      "\n",
      "+--------+-----+--------------------+--------------------+----------+\n",
      "| message|label|       rawPrediction|         probability|prediction|\n",
      "+--------+-----+--------------------+--------------------+----------+\n",
      "|LETSGOOO|  0.0|[8.88758229630753...|[0.51292127140227...|       0.0|\n",
      "+--------+-----+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
